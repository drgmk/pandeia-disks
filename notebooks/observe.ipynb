{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the observations\n",
    "Run these in a handful of filters and with/without coronagraphy.\n",
    "Here we assume that the scene has been created elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "\n",
    "import pandisk as pd\n",
    "import pandeia.engine\n",
    "import jwst_pancake as pc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base observation config\n",
    "cor_base = pandeia.engine.calc_utils.build_default_calc('jwst', 'miri', 'coronagraphy')\n",
    "cor_base['scene'].clear()\n",
    "\n",
    "img_base = pandeia.engine.calc_utils.build_default_calc('jwst', 'miri', 'imaging')\n",
    "img_base['scene'].clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of setups, change number of groups to limit imaging saturation,\n",
    "# but avoid going below 5\n",
    "# https://jwst-docs.stsci.edu/display/JPP/MIRI+Generic+Recommended+Strategies\n",
    "img_sub = 'sub256' #30\" sqaure\n",
    "subarrays  = [ img_sub, 'mask1065',  img_sub, 'mask1550',  img_sub, 'masklyot',  img_sub,  img_sub]\n",
    "apertures  = ['imager', 'fqpm1065', 'imager', 'fqpm1550', 'imager', 'lyot2300', 'imager', 'imager']\n",
    "filters    = ['f1000w', 'f1065c',   'f1500w', 'f1550c',   'f1800w', 'f2300c',   'f2100w', 'f2550w']\n",
    "targ_ngrps = [ 5,        100,        7,        100,        7,        100,        7,        10]\n",
    "ref_ngrps  = [ 5,        100,        5,        100,        5,        100,        5,        10]\n",
    "\n",
    "# copy the above and delete as appropriate\n",
    "subarrays  = ['mask1065',  img_sub, 'mask1550', 'masklyot',  img_sub]\n",
    "apertures  = ['fqpm1065', 'imager', 'fqpm1550', 'lyot2300', 'imager']\n",
    "filters    = ['f1065c',   'f1500w', 'f1550c',   'f2300c',   'f2550w']\n",
    "targ_ngrps = [ 100,        7,        100,        100,        10]\n",
    "ref_ngrps  = [ 100,        5,        100,        100,        10]\n",
    "\n",
    "# nint will be this/ngroups, 10,000 is approx 40-50 minutes\n",
    "# for MIRI coron and sub256 subarrays\n",
    "target_int = 10000\n",
    "ref_int    = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scene - this is the science object\n",
    "scene_dir = './' #'../../../cycle1/hd38858/'\n",
    "with open(scene_dir+'targ.json','r') as f:\n",
    "    targ_scene = json.load(f)\n",
    "    \n",
    "# add in a global offset to capture the effect of target acquisition error.\n",
    "errx, erry = pc.scene.get_ta_error()\n",
    "pc.scene.offset_scene(targ_scene,errx,erry)\n",
    "\n",
    "# same for reference star\n",
    "ref_scene = copy.deepcopy(targ_scene)\n",
    "with open(scene_dir+'ref.json','r') as f:\n",
    "    ref_scene = json.load(f)\n",
    "    \n",
    "# And add target acquisition error\n",
    "errx_ref, erry_ref = pc.scene.get_ta_error()\n",
    "pc.scene.offset_scene(ref_scene,errx_ref,erry_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list, one element per observation\n",
    "target = []\n",
    "targ_star = []\n",
    "ref_star = []\n",
    "for suba, aper, filt, tngrp, rngrp in zip(subarrays, apertures, filters, targ_ngrps, ref_ngrps):\n",
    "\n",
    "    if aper == 'imager':\n",
    "        targ = copy.deepcopy(img_base)\n",
    "        targ['configuration']['dynamic_image'] = True\n",
    "        targ['configuration']['scene_size'] = 15.0\n",
    "    else:\n",
    "        targ = copy.deepcopy(cor_base)\n",
    "        \n",
    "    # target\n",
    "    targ['configuration']['detector']['subarray'] = suba\n",
    "    targ['configuration']['instrument']['aperture'] = aper\n",
    "    targ['configuration']['instrument']['filter'] = filt\n",
    "    targ['configuration']['detector']['ngroup'] = tngrp\n",
    "    targ['configuration']['detector']['nint'] = target_int / tngrp\n",
    "    targ['configuration']['detector']['readmode'] = 'fast'\n",
    "    targ['scene'] = copy.deepcopy(targ_scene)\n",
    "\n",
    "    # target star by itself\n",
    "    star = copy.deepcopy(targ)\n",
    "    star['scene'] = star['scene'][:1]\n",
    "    \n",
    "    # reference star\n",
    "    ref = copy.deepcopy(targ)\n",
    "    ref['configuration']['detector']['ngroup'] = rngrp\n",
    "    ref['configuration']['detector']['nint'] = ref_int / rngrp\n",
    "    ref['scene'] = copy.deepcopy(ref_scene)\n",
    "    \n",
    "    target.append(targ)\n",
    "    targ_star.append(star)\n",
    "    ref_star.append(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional calculation config, if we're using pandeia_coronagraphy\n",
    "pc.engine.options.wave_sampling = 10        # set ~10 for speed, >50 for accuracy\n",
    "pc.engine.options.on_the_fly_PSFs = False   # True to get on-the-fly PSFs, only works for coron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pandeia calculation, pandeia-coronagraphy package includes realistic noise \n",
    "# by not fixing a random seed\n",
    "def calculate_batch(calcfiles, nprocesses=None):\n",
    "    if nprocesses is None:\n",
    "        nprocesses = mp.cpu_count()\n",
    "    pool = mp.Pool(processes = nprocesses)\n",
    "#     results = pool.map(pandeia.engine.perform_calculation.perform_calculation, calcfiles)\n",
    "    results = pool.map(pc.engine.perform_calculation, calcfiles)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/astroconda/lib/python3.7/site-packages/astropy/units/quantity.py:477: RuntimeWarning: overflow encountered in multiply\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n",
      "/usr/local/miniconda3/envs/astroconda/lib/python3.7/site-packages/astropy/units/quantity.py:477: RuntimeWarning: overflow encountered in multiply\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n",
      "/usr/local/miniconda3/envs/astroconda/lib/python3.7/site-packages/astropy/units/quantity.py:477: RuntimeWarning: overflow encountered in multiply\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n",
      "/usr/local/miniconda3/envs/astroconda/lib/python3.7/site-packages/astropy/units/quantity.py:477: RuntimeWarning: overflow encountered in multiply\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "/usr/local/miniconda3/envs/astroconda/lib/python3.7/site-packages/astropy/units/quantity.py:477: RuntimeWarning: overflow encountered in multiply\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n",
      "WARNING: Source spectrum will be extrapolated (at constant value for empirical model). [synphot.observation]\n",
      "WARNING:astropy:Source spectrum will be extrapolated (at constant value for empirical model).\n"
     ]
    }
   ],
   "source": [
    "# do the calculation, gives quite a few warnings\n",
    "results = calculate_batch(target+targ_star+ref_star)\n",
    "target_results = results[:len(target)]\n",
    "star_results = results[len(target):len(target)+len(targ_star)]\n",
    "ref_results = results[len(target)+len(targ_star):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some relevant images\n",
    "target_slope = []\n",
    "target_snr = []\n",
    "target_sat = []\n",
    "star_slope = []\n",
    "star_snr = []\n",
    "star_sat = []\n",
    "ref_slope = []\n",
    "ref_snr = []\n",
    "ref_sat = []\n",
    "for t, s, r in zip(target_results, star_results, ref_results):\n",
    "    target_slope.append(t['2d']['detector'])\n",
    "    target_snr.append(t['2d']['snr'])\n",
    "    target_sat.append(t['2d']['saturation'])\n",
    "    star_slope.append(s['2d']['detector'])\n",
    "    star_snr.append(s['2d']['snr'])\n",
    "    star_sat.append(s['2d']['saturation'])\n",
    "    ref_slope.append(r['2d']['detector'])\n",
    "    ref_snr.append(r['2d']['snr'])\n",
    "    ref_sat.append(r['2d']['saturation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the results\n",
    "PSF is not properly generated for imaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target slope images\n",
    "pd.show_images(target_slope, title=list(zip(filters,np.tile('e/s',len(filters)))))\n",
    "pd.show_images(target_snr, title=list(zip(filters,np.tile('snr',len(filters)))), log=False)\n",
    "pd.show_images(target_snr, title=list(zip(filters,np.tile('snr',len(filters)))), log=True)\n",
    "pd.show_images(target_sat, title=list(zip(filters,np.tile('sat',len(filters)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star slope images\n",
    "pd.show_images(star_slope, title=list(zip(filters,np.tile('e/s',len(filters)))))\n",
    "pd.show_images(star_snr, title=list(zip(filters,np.tile('snr',len(filters)))))\n",
    "pd.show_images(star_sat, title=list(zip(filters,np.tile('sat',len(filters)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference slope images\n",
    "pd.show_images(ref_slope, title=list(zip(filters,np.tile('e/s',len(filters)))))\n",
    "pd.show_images(ref_snr, title=list(zip(filters,np.tile('snr',len(filters)))))\n",
    "pd.show_images(ref_sat, title=list(zip(filters,np.tile('sat',len(filters)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtraction in perfect case; reference is target star\n",
    "pd.show_images(target_slope, sub=star_slope, title=list(zip(filters,np.tile('perfect sub',len(filters)))))\n",
    "pd.show_images(target_slope, sub=star_slope, title=list(zip(filters,np.tile('perfect sub',len(filters)))), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference subtraction without recentering\n",
    "norm = [np.nanmax(target_slope[i])/np.nanmax(ref_slope[i]) for i in range(len(target_slope))]\n",
    "sub = [r*n for r,n in zip(ref_slope, norm)]\n",
    "\n",
    "pd.show_images(target_slope, sub=sub, title=list(zip(filters,np.tile('psf sub',len(filters)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# registered subtraction\n",
    "reg_ref = []\n",
    "target_bg = []\n",
    "for t,r in zip(target_slope, ref_slope):\n",
    "    clean_targ = t.copy()\n",
    "    clean_targ[np.isnan(t)] = np.nanmax(t)\n",
    "    clean_targ -= np.percentile(clean_targ, 30)\n",
    "    clean_ref = r.copy()\n",
    "    clean_ref[np.isnan(r)] = np.nanmax(r)\n",
    "    clean_ref -= np.percentile(clean_ref, 30)\n",
    "    reg_ref.append(pc.analysis.register_to_target(clean_ref, clean_targ, rescale_reference=True))\n",
    "    target_bg.append(clean_targ - np.percentile(clean_targ, 30))\n",
    "\n",
    "pd.show_images(target_bg, sub=reg_ref, title=list(zip(filters,np.tile('psf sub',len(filters)))))\n",
    "pd.show_images(target_bg, sub=reg_ref, title=list(zip(filters,np.tile('psf sub',len(filters)))), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "with open('pandeia-results.pkl','wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
